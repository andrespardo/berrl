{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing Berrl Implementation in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON file written to location: fatals.geojson\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:8000/index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x108ef9a50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import berrl as bl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "apikey='pk.eyJ1IjoibXVycGh5MjE0IiwiYSI6ImNpam5kb3puZzAwZ2l0aG01ZW1uMTRjbnoifQ.5Znb4MArp7v3Wwrn6WFE6A'\n",
    "data=pd.read_csv('wv_traffic_fatals.csv')\n",
    "#data=data[data.CNTYNAME=='Clay County']\n",
    "\n",
    "a=bl.make_points(data,list=True)\n",
    "bl.parselist(a,'fatals.geojson')\n",
    "\n",
    "# returns url to be used in show() function\n",
    "url=bl.loadparsehtml(['fatals.geojson'],apikey,frame=True)\n",
    "bl.show(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON file written to location: 1.geojson\n",
      "GeoJSON file written to location: 2.geojson\n",
      "GeoJSON file written to location: 3.geojson\n",
      "GeoJSON file written to location: 4.geojson\n",
      "GeoJSON file written to location: 5.geojson\n",
      "GeoJSON file written to location: 6.geojson\n",
      "GeoJSON file written to location: 7.geojson\n",
      "GeoJSON file written to location: 8.geojson\n",
      "GeoJSON file written to location: 9.geojson\n",
      "GeoJSON file written to location: 10.geojson\n",
      "GeoJSON file written to location: 11.geojson\n",
      "GeoJSON file written to location: 12.geojson\n",
      "GeoJSON file written to location: 13.geojson\n",
      "GeoJSON file written to location: 14.geojson\n",
      "GeoJSON file written to location: 15.geojson\n",
      "GeoJSON file written to location: 16.geojson\n",
      "GeoJSON file written to location: 17.geojson\n",
      "GeoJSON file written to location: 18.geojson\n",
      "GeoJSON file written to location: 19.geojson\n",
      "GeoJSON file written to location: 20.geojson\n",
      "GeoJSON file written to location: 21.geojson\n",
      "GeoJSON file written to location: 22.geojson\n",
      "GeoJSON file written to location: 23.geojson\n",
      "GeoJSON file written to location: 24.geojson\n",
      "GeoJSON file written to location: 25.geojson\n",
      "GeoJSON file written to location: 26.geojson\n",
      "GeoJSON file written to location: 27.geojson\n",
      "GeoJSON file written to location: 28.geojson\n",
      "GeoJSON file written to location: 29.geojson\n",
      "GeoJSON file written to location: 30.geojson\n",
      "GeoJSON file written to location: 31.geojson\n",
      "GeoJSON file written to location: 32.geojson\n",
      "GeoJSON file written to location: 33.geojson\n"
     ]
    }
   ],
   "source": [
    "# getting only the fatalities on certain routes\n",
    "roadways=bl.get_filetype('roadways','csv')\n",
    "totaluniques=[]\n",
    "count=0\n",
    "filenames=[]\n",
    "for row in roadways:\n",
    "    count+=1\n",
    "    temp=bl.map_table(row,6)\n",
    "    uniques=np.unique(temp['GEOHASH']).tolist()\n",
    "    totaluniques+=uniques\n",
    "    temp['color']='light green'\n",
    "    a=bl.make_line(temp,list=True)\n",
    "    bl.parselist(a,str(count)+'.geojson')\n",
    "    filenames.append(str(count)+'.geojson')\n",
    "\n",
    "totaluniques=np.unique(totaluniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping all fatalities and getting unique hashs for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON file written to location: 34.geojson\n",
      "GeoJSON file written to location: 35.geojson\n",
      "GeoJSON file written to location: 36.geojson\n",
      "GeoJSON file written to location: 37.geojson\n",
      "GeoJSON file written to location: 38.geojson\n",
      "GeoJSON file written to location: 39.geojson\n",
      "GeoJSON file written to location: 40.geojson\n",
      "GeoJSON file written to location: 41.geojson\n",
      "GeoJSON file written to location: 42.geojson\n",
      "GeoJSON file written to location: 43.geojson\n",
      "GeoJSON file written to location: 44.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# mapping all traffic fatals in WV to a geohash\n",
    "data=bl.map_table(data,6,list=True)\n",
    "\n",
    "matched=[]\n",
    "# getting matching uniques\n",
    "for row in bl.df2list(data):\n",
    "    oldrow=row\n",
    "    for row in totaluniques:\n",
    "        if oldrow[-1]==row:\n",
    "            matched.append(row)\n",
    "\n",
    "# getting point\n",
    "for row in matched:\n",
    "    count+=1\n",
    "    temp=data[data.GEOHASH==row]\n",
    "    temp['color']='red'\n",
    "    a=bl.make_points(temp,list=True)\n",
    "    bl.parselist(a,str(count)+'.geojson')\n",
    "    filenames.append(str(count)+'.geojson')\n",
    "\n",
    "newurl=bl.loadparsehtml(filenames,apikey,colorkey='color',frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing the new url made with fatalities along certain routes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:8000/index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x104a9aa50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl.show(newurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
